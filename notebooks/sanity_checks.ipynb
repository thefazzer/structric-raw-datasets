{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structric Raw Datasets - Sanity Checks\n",
    "\n",
    "This notebook validates the exported datasets without modifying them.\n",
    "\n",
    "**Purpose**: Verify data integrity, coverage, and distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Connect to DuckDB with spatial extension\n",
    "conn = duckdb.connect(':memory:')\n",
    "conn.execute(\"INSTALL spatial; LOAD spatial;\")\n",
    "\n",
    "PARCELS_PATH = '../data/parcels_raw.parquet'\n",
    "BUILDINGS_PATH = '../data/buildings_raw.parquet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parcels overview\n",
    "parcels_stats = conn.execute(f\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) as total_parcels,\n",
    "        COUNT(DISTINCT county) as counties,\n",
    "        COUNT(DISTINCT city) as cities,\n",
    "        MIN(area_sqft) as min_area,\n",
    "        MAX(area_sqft) as max_area,\n",
    "        AVG(area_sqft) as mean_area,\n",
    "        APPROX_QUANTILE(area_sqft, 0.5) as median_area,\n",
    "        SUM(CASE WHEN zoning_raw IS NOT NULL THEN 1 ELSE 0 END) as has_zoning,\n",
    "        SUM(CASE WHEN inferred_flag THEN 1 ELSE 0 END) as inferred_count\n",
    "    FROM read_parquet('{PARCELS_PATH}')\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PARCELS DATASET\")\n",
    "print(\"=\" * 60)\n",
    "print(parcels_stats.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buildings overview\n",
    "buildings_stats = conn.execute(f\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) as total_buildings,\n",
    "        MIN(footprint_area_sqft) as min_area,\n",
    "        MAX(footprint_area_sqft) as max_area,\n",
    "        AVG(footprint_area_sqft) as mean_area,\n",
    "        APPROX_QUANTILE(footprint_area_sqft, 0.5) as median_area,\n",
    "        AVG(ms_confidence) as mean_confidence,\n",
    "        SUM(CASE WHEN parcel_apn IS NOT NULL THEN 1 ELSE 0 END) as linked_to_parcel,\n",
    "        SUM(CASE WHEN inferred_flag THEN 1 ELSE 0 END) as inferred_count\n",
    "    FROM read_parquet('{BUILDINGS_PATH}')\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"BUILDINGS DATASET\")\n",
    "print(\"=\" * 60)\n",
    "print(buildings_stats.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Geographic Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# County distribution\n",
    "county_dist = conn.execute(f\"\"\"\n",
    "    SELECT county, COUNT(*) as parcel_count\n",
    "    FROM read_parquet('{PARCELS_PATH}')\n",
    "    GROUP BY county\n",
    "    ORDER BY parcel_count DESC\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(\"Top 15 Counties by Parcel Count:\")\n",
    "print(county_dist.head(15).to_string(index=False))\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "county_dist.head(20).plot.bar(x='county', y='parcel_count', ax=ax)\n",
    "ax.set_title('Parcel Count by County (Top 20)')\n",
    "ax.set_xlabel('County')\n",
    "ax.set_ylabel('Parcel Count')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bounding box check\n",
    "bbox = conn.execute(f\"\"\"\n",
    "    SELECT \n",
    "        MIN(ST_XMin(ST_GeomFromWKB(geometry_wkb))) as min_lon,\n",
    "        MAX(ST_XMax(ST_GeomFromWKB(geometry_wkb))) as max_lon,\n",
    "        MIN(ST_YMin(ST_GeomFromWKB(geometry_wkb))) as min_lat,\n",
    "        MAX(ST_YMax(ST_GeomFromWKB(geometry_wkb))) as max_lat\n",
    "    FROM read_parquet('{PARCELS_PATH}')\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(\"\\nParcels Bounding Box:\")\n",
    "print(f\"  Longitude: {bbox['min_lon'][0]:.4f} to {bbox['max_lon'][0]:.4f}\")\n",
    "print(f\"  Latitude: {bbox['min_lat'][0]:.4f} to {bbox['max_lat'][0]:.4f}\")\n",
    "\n",
    "# California bbox should be roughly: -124.5 to -114, 32.5 to 42\n",
    "print(\"\\nExpected California bbox: -124.5 to -114, 32.5 to 42\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Geometry Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for invalid geometries in parcels\n",
    "parcel_geom_check = conn.execute(f\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) as total,\n",
    "        SUM(CASE WHEN geometry_wkb IS NULL THEN 1 ELSE 0 END) as null_geom,\n",
    "        SUM(CASE WHEN NOT ST_IsValid(ST_GeomFromWKB(geometry_wkb)) THEN 1 ELSE 0 END) as invalid_geom,\n",
    "        SUM(CASE WHEN ST_IsEmpty(ST_GeomFromWKB(geometry_wkb)) THEN 1 ELSE 0 END) as empty_geom\n",
    "    FROM read_parquet('{PARCELS_PATH}')\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(\"Parcel Geometry Validation:\")\n",
    "print(parcel_geom_check.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for invalid geometries in buildings (sample for performance)\n",
    "building_geom_check = conn.execute(f\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) as total,\n",
    "        SUM(CASE WHEN geometry_wkb IS NULL THEN 1 ELSE 0 END) as null_geom,\n",
    "        SUM(CASE WHEN NOT ST_IsValid(ST_GeomFromWKB(geometry_wkb)) THEN 1 ELSE 0 END) as invalid_geom\n",
    "    FROM read_parquet('{BUILDINGS_PATH}')\n",
    "    USING SAMPLE 100000\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(\"Building Geometry Validation (100K sample):\")\n",
    "print(building_geom_check.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Area Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parcel area distribution\n",
    "parcel_areas = conn.execute(f\"\"\"\n",
    "    SELECT area_sqft\n",
    "    FROM read_parquet('{PARCELS_PATH}')\n",
    "    WHERE area_sqft < 100000  -- Focus on typical residential\n",
    "    USING SAMPLE 50000\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(parcel_areas['area_sqft'], bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_title('Parcel Area Distribution (< 100K sqft)')\n",
    "axes[0].set_xlabel('Area (sqft)')\n",
    "axes[0].set_ylabel('Count')\n",
    "\n",
    "# Log scale\n",
    "axes[1].hist(parcel_areas['area_sqft'], bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[1].set_title('Parcel Area Distribution (log scale)')\n",
    "axes[1].set_xlabel('Area (sqft)')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building footprint area distribution\n",
    "building_areas = conn.execute(f\"\"\"\n",
    "    SELECT footprint_area_sqft\n",
    "    FROM read_parquet('{BUILDINGS_PATH}')\n",
    "    WHERE footprint_area_sqft < 10000  -- Focus on typical buildings\n",
    "    USING SAMPLE 50000\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(building_areas['footprint_area_sqft'], bins=50, edgecolor='black', alpha=0.7, color='orange')\n",
    "axes[0].set_title('Building Footprint Distribution (< 10K sqft)')\n",
    "axes[0].set_xlabel('Footprint Area (sqft)')\n",
    "axes[0].set_ylabel('Count')\n",
    "\n",
    "# Log scale\n",
    "axes[1].hist(building_areas['footprint_area_sqft'], bins=50, edgecolor='black', alpha=0.7, color='orange')\n",
    "axes[1].set_title('Building Footprint Distribution (log scale)')\n",
    "axes[1].set_xlabel('Footprint Area (sqft)')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Provenance Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify all provenance fields are populated\n",
    "parcel_provenance = conn.execute(f\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) as total,\n",
    "        SUM(CASE WHEN source_system IS NULL THEN 1 ELSE 0 END) as null_source_system,\n",
    "        SUM(CASE WHEN source_table IS NULL THEN 1 ELSE 0 END) as null_source_table,\n",
    "        SUM(CASE WHEN source_id IS NULL THEN 1 ELSE 0 END) as null_source_id,\n",
    "        SUM(CASE WHEN spatial_resolution IS NULL THEN 1 ELSE 0 END) as null_resolution,\n",
    "        SUM(CASE WHEN ingested_at IS NULL THEN 1 ELSE 0 END) as null_ingested_at,\n",
    "        SUM(CASE WHEN license_note IS NULL THEN 1 ELSE 0 END) as null_license\n",
    "    FROM read_parquet('{PARCELS_PATH}')\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(\"Parcel Provenance Field Completeness:\")\n",
    "print(parcel_provenance.T)\n",
    "print(\"\\n(All values should be 0 except 'total')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify buildings provenance\n",
    "building_provenance = conn.execute(f\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) as total,\n",
    "        SUM(CASE WHEN source_system IS NULL THEN 1 ELSE 0 END) as null_source_system,\n",
    "        SUM(CASE WHEN source_table IS NULL THEN 1 ELSE 0 END) as null_source_table,\n",
    "        SUM(CASE WHEN building_source IS NULL THEN 1 ELSE 0 END) as null_building_source,\n",
    "        SUM(CASE WHEN spatial_resolution IS NULL THEN 1 ELSE 0 END) as null_resolution,\n",
    "        SUM(CASE WHEN ingested_at IS NULL THEN 1 ELSE 0 END) as null_ingested_at,\n",
    "        SUM(CASE WHEN license_note IS NULL THEN 1 ELSE 0 END) as null_license\n",
    "    FROM read_parquet('{BUILDINGS_PATH}')\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(\"Building Provenance Field Completeness:\")\n",
    "print(building_provenance.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cross-Source Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare parcel count to building count by rough geographic area\n",
    "# This is NOT a linkage - just a sanity check on relative densities\n",
    "\n",
    "print(\"Rough density comparison (buildings per parcel):\")\n",
    "print(f\"  Total parcels: 2,626,755\")\n",
    "print(f\"  Total buildings: 11,542,719\")\n",
    "print(f\"  Ratio: {11542719 / 2626755:.2f} buildings per parcel\")\n",
    "print(\"\\nNote: This is a rough average. Actual linkage would require spatial join.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Quality Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check inference flags\n",
    "print(\"Inference Flag Summary:\")\n",
    "print(\"\\nParcels:\")\n",
    "parcel_inferred = conn.execute(f\"\"\"\n",
    "    SELECT inferred_flag, COUNT(*) as count\n",
    "    FROM read_parquet('{PARCELS_PATH}')\n",
    "    GROUP BY inferred_flag\n",
    "\"\"\").fetchdf()\n",
    "print(parcel_inferred.to_string(index=False))\n",
    "\n",
    "print(\"\\nBuildings:\")\n",
    "building_inferred = conn.execute(f\"\"\"\n",
    "    SELECT inferred_flag, COUNT(*) as count\n",
    "    FROM read_parquet('{BUILDINGS_PATH}')\n",
    "    GROUP BY inferred_flag\n",
    "\"\"\").fetchdf()\n",
    "print(building_inferred.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MS Confidence distribution\n",
    "confidence_dist = conn.execute(f\"\"\"\n",
    "    SELECT \n",
    "        ROUND(ms_confidence, 2) as confidence_bucket,\n",
    "        COUNT(*) as count\n",
    "    FROM read_parquet('{BUILDINGS_PATH}')\n",
    "    GROUP BY 1\n",
    "    ORDER BY 1\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(\"Microsoft Confidence Score Distribution:\")\n",
    "print(confidence_dist.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary\n",
    "\n",
    "### Validation Checklist\n",
    "\n",
    "- [ ] Row counts match expected values\n",
    "- [ ] No NULL geometries\n",
    "- [ ] No invalid geometries\n",
    "- [ ] Bounding box within California\n",
    "- [ ] Area distributions are reasonable\n",
    "- [ ] All provenance fields populated\n",
    "- [ ] No unexpected inferred flags\n",
    "- [ ] Buildings NOT linked to parcels (parcel_apn always NULL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"=\" * 60)\n",
    "print(\"SANITY CHECK SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nParcels: 2,626,755 records across 33 counties\")\n",
    "print(f\"Buildings: 11,542,719 records (Microsoft footprints)\")\n",
    "print(f\"\\nKey observations:\")\n",
    "print(f\"  - No parcel-building linkage (by design)\")\n",
    "print(f\"  - No zoning data (not in source)\")\n",
    "print(f\"  - No height/stories data (not in MS footprints)\")\n",
    "print(f\"  - All provenance fields populated\")\n",
    "print(f\"  - No inferred data (inferred_flag = FALSE for all)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
